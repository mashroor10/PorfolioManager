{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fe767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import time\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_quarterly_data(url_base, ticker, api_key, period):\n",
    "    params = {\n",
    "        'symbol': ticker,\n",
    "        'period': period,\n",
    "        'limit': 20,\n",
    "        'apikey': api_key,\n",
    "    }\n",
    "    full_url = f\"{url_base}?{'&'.join([f'{key}={value}' for key, value in params.items()])}\"\n",
    "    response = requests.get(full_url)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            df = pd.DataFrame(response.json())\n",
    "            if not df.empty:\n",
    "                df['date'] = pd.to_datetime(df['date'])\n",
    "                df['period'] = period\n",
    "            return df\n",
    "        except ValueError:\n",
    "            print(f\"JSON decoding failed for {url_base} - {period}\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Request failed for {url_base} - {period}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def GetAllFundamentalData(ticker, api_key):\n",
    "    income_url = \"https://financialmodelingprep.com/stable/income-statement\"\n",
    "    balance_url = \"https://financialmodelingprep.com/stable/balance-sheet-statement\"\n",
    "    cashflow_url = \"https://financialmodelingprep.com/stable/cash-flow-statement\"\n",
    "    \n",
    "    all_income, all_balance, all_cash = [], [], []\n",
    "\n",
    "    for period in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "        income_df = get_quarterly_data(income_url, ticker, api_key, period)\n",
    "        balance_df = get_quarterly_data(balance_url, ticker, api_key, period)\n",
    "        cashflow_df = get_quarterly_data(cashflow_url, ticker, api_key, period)\n",
    "\n",
    "        if not (income_df.empty or balance_df.empty or cashflow_df.empty):\n",
    "            # Align columns before merge\n",
    "            for df in [income_df, balance_df, cashflow_df]:\n",
    "                df.set_index('date', inplace=True)\n",
    "\n",
    "            # Inner merge to keep only matching dates across all statements\n",
    "            merged = income_df.join(balance_df, how='inner', lsuffix='_income', rsuffix='_balance')\n",
    "            merged = merged.join(cashflow_df, how='inner', rsuffix='_cashflow')\n",
    "\n",
    "            merged.reset_index(inplace=True)\n",
    "            merged['period'] = period\n",
    "            all_income.append(merged)\n",
    "\n",
    "    if all_income:\n",
    "        final_df = pd.concat(all_income, ignore_index=True)\n",
    "        final_df.sort_values(by='date', inplace=True)\n",
    "\n",
    "        directory = \"Fundamentals\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = os.path.join(directory, f\"{ticker}_all_fundamentals.csv\")\n",
    "        final_df.to_csv(filename, index=False)\n",
    "        print(f\"Saved combined fundamental data to {filename}\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"No combined data found for given periods.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage\n",
    "ticker = \"AAPL\"\n",
    "api_key = os.getenv(\"api_key\")\n",
    "df = GetAllFundamentalData(ticker, api_key)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad70495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get30MinData(apiKey, ticker, end):\n",
    "    def push_to_pgsql(df, ticker):\n",
    "        table_name = f\"{ticker}_30MinData\"\n",
    "\n",
    "        # Database connection details (from Docker Compose)\n",
    "        db_params = {\n",
    "            'user': os.getenv('user'),\n",
    "            'password': os.getenv('password'),\n",
    "            'host': os.getenv('host'),\n",
    "            'port': os.getenv('port'),\n",
    "            'dbname': os.getenv('dbname')\n",
    "        }\n",
    "\n",
    "        # SQLAlchemy connection string (using postgresql dialect)\n",
    "        engine_str = (\n",
    "            f\"postgresql://{db_params['user']}:{db_params['password']}\"\n",
    "            f\"@{db_params['host']}:{db_params['port']}/{db_params['dbname']}\"\n",
    "        )\n",
    "\n",
    "        # Create SQLAlchemy engine\n",
    "        engine = create_engine(engine_str)\n",
    "\n",
    "        try:\n",
    "            df.to_sql(table_name, engine, if_exists='replace', index=False, method='multi')\n",
    "            print(f\"âœ… Data successfully written to table '{table_name}' in PostgreSQL.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to write data to PostgreSQL: {e}\")\n",
    "    def get_ipo_date(ticker, api_key):\n",
    "        url = f\"https://financialmodelingprep.com/stable/profile?symbol={ticker}&apikey={api_key}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                ipo_date = data[0].get('ipoDate')\n",
    "                if ipo_date:\n",
    "                    return ipo_date\n",
    "            except (KeyError, IndexError, ValueError):\n",
    "                print(f\"âš ï¸ Failed to parse IPO date for {ticker}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ Failed to fetch IPO info. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Initialize rate limiter state\n",
    "    rate_limiter = {\n",
    "        'start_time': time.time(),\n",
    "        'call_count': 0\n",
    "    }\n",
    "    \n",
    "    def rate_limited_get(url, params):\n",
    "        \"\"\"Make API calls while respecting the rate limit\"\"\"\n",
    "        nonlocal rate_limiter\n",
    "        \n",
    "        # Calculate time since last reset\n",
    "        elapsed = time.time() - rate_limiter['start_time']\n",
    "        \n",
    "        # Handle rate limiting\n",
    "        if rate_limiter['call_count'] >= 290:  # Using 290 for safety buffer\n",
    "            if elapsed < 60:\n",
    "                # Calculate precise wait time\n",
    "                wait_time = 60.01 - elapsed  # Add 10ms buffer\n",
    "                print(f\"â³ API limit reached. Waiting {wait_time:.2f} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            \n",
    "            # Reset counter after waiting\n",
    "            rate_limiter['start_time'] = time.time()\n",
    "            rate_limiter['call_count'] = 0\n",
    "            print(\"â™»ï¸ Rate limit counter reset\")\n",
    "        \n",
    "        # Make the API call\n",
    "        rate_limiter['call_count'] += 1\n",
    "        print(f\"ðŸ“ž API call #{rate_limiter['call_count']} (Elapsed: {elapsed:.2f}s)\")\n",
    "        finalurl =  f\"{url}?{'&'.join([f'{key}={value}' for key, value in params.items()])}\"\n",
    "        print(f\"ðŸ”— Request URL: {finalurl}\")\n",
    "        \n",
    "        return requests.get(finalurl)\n",
    "    \n",
    "    def pullData(ticker, apiKey, start, end, period = '30min'):\n",
    "        #putting a switch case for 30mins and daily data url\n",
    "        if period == '30min':\n",
    "            base_url = \"https://financialmodelingprep.com/stable/historical-chart/30min\"\n",
    "        elif period == 'daily':\n",
    "            base_url = \"https://financialmodelingprep.com/stable/historical-price-eod/full\"\n",
    "        else:\n",
    "            raise ValueError(\"Invalid period. Use '30mins' or 'daily'.\")\n",
    "        \n",
    "        \n",
    "        params = {\n",
    "            'to': end,\n",
    "            'from': start,\n",
    "            'symbol': ticker,\n",
    "            'apikey': apiKey,\n",
    "        }\n",
    "        \n",
    "        response = rate_limited_get(base_url, params=params)\n",
    "        \n",
    "        # Check for successful response\n",
    "        if response.status_code != 200:\n",
    "            print(f\"âš ï¸ Error {response.status_code} for {start} to {end}\")\n",
    "        print(f\"ðŸ“¥ Downloaded data for {ticker} from {start} to {end} ({period})\")\n",
    "            \n",
    "        data = response.json()\n",
    "        #converting the data to a pandas dataframe\n",
    "        df = pd.DataFrame(data)\n",
    "        #getting the earliest and latest date from the data\n",
    "        if len(df) == 0:\n",
    "            print(f\"No data found for {ticker} from {start} to {end}.\")\n",
    "            return pd.DataFrame(), start\n",
    "        earliestDate = df['date'].min()\n",
    "        latestDate = df['date'].max()\n",
    "        \n",
    "        print(f\"ðŸ“… Earliest date: {earliestDate}, Latest date: {latestDate}\")\n",
    "        \n",
    "        #dropping the high and low columns if they exist\n",
    "        if 'high' in df.columns and 'low' in df.columns:\n",
    "            df = df.drop(columns=['high', 'low'])\n",
    "        #drop 'change', 'changePercent' and 'vwap' columns if they exist\n",
    "        if 'change' in df.columns and 'changePercent' in df.columns and 'vwap' in df.columns:\n",
    "            df = df.drop(columns=['change', 'changePercent', 'vwap'])\n",
    "            print(\"Dropped 'change', 'changePercent', and 'vwap' columns.\")\n",
    "            print(\"the length of the dataframe is: \", len(df))\n",
    "        \n",
    "        #getting the earliest Date and removing the time part\n",
    "        if period == '30min':\n",
    "            earliestDate = earliestDate.split(' ')[0]\n",
    "        #converting the date to a datetime object\n",
    "        earliestDate = datetime.strptime(earliestDate, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "        \n",
    "        #returning the dataframe and the earliest date\n",
    "        return df, earliestDate\n",
    "    \n",
    "    def addLastEntry(df, current):\n",
    "        dataFrame=df \n",
    "        for idx, row in current.iterrows():\n",
    "            # getting the date from the current row\n",
    "            date_str = row['date']\n",
    "            \n",
    "            # finding the row in dataFrame with this date %Y-%m-%d 15:30:00\n",
    "            match_row = dataFrame[dataFrame['date'] == date_str.split(' ')[0] + ' 15:30:00']\n",
    "            \n",
    "            # converting the date to a datetime object with hour set to 16:00:00\n",
    "            date = datetime.strptime(date_str.split(' ')[0], '%Y-%m-%d') + timedelta(hours=16)\n",
    "            \n",
    "            # setting the \"open\" value of the current day to the \"close\" value of match_row\n",
    "            if not match_row.empty:\n",
    "                open_value = match_row['close'].values[0]\n",
    "            else:\n",
    "                open_value = None\n",
    "            \n",
    "            # adding the row to the dataframe with the date set to 16:00:00\n",
    "            new_row = pd.DataFrame([{\n",
    "                'date': date.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'open': open_value,\n",
    "                'close': row['close'],\n",
    "                'volume': row['volume']\n",
    "            }])\n",
    "            dataFrame = pd.concat([dataFrame, new_row], ignore_index=True)\n",
    "            \n",
    "        return dataFrame\n",
    "    \n",
    "    #the data is stored in a pandas dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #converting the start and end dates to datetime strings with date and hour format %Y-%m-%d\n",
    "    # Get IPO date for the ticker and use it as the start date\n",
    "    ipoDate = get_ipo_date(ticker, apiKey)\n",
    "    if ipoDate is None:\n",
    "        raise ValueError(f\"Could not retrieve IPO date for {ticker}\")\n",
    "        return None\n",
    "    \n",
    "    start = datetime.strptime(ipoDate, '%Y-%m-%d')\n",
    "    end = datetime.strptime(end, '%Y-%m-%d')\n",
    "    \n",
    "    #remove the hour component from the start and end dates\n",
    "    start = start.strftime('%Y-%m-%d')\n",
    "    end = end.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"Getting data for {ticker} from {start} to {end}\")\n",
    "    \n",
    "    currentEnd = []\n",
    "    currentEnd.append(end)\n",
    "    #getting the earliest date in currentEnd\n",
    "    while start not in currentEnd:\n",
    "        #get the data for the current date\n",
    "        currentData, earliestDate = pullData(ticker, apiKey, start=start, end=currentEnd, period = '30min')\n",
    "        print(f\"Length of currentData: {len(currentData)}\")\n",
    "        \n",
    "        # If earliestDate is the same as currentEnd, set currentEnd to 15:30:00 of the day before earliestDate\n",
    "        \n",
    "        #remove the hour component from earliestDate\n",
    "        earliestDate = earliestDate.split(' ')[0]\n",
    "        if earliestDate in currentEnd:\n",
    "            prev_day = datetime.strptime(earliestDate, '%Y-%m-%d') - timedelta(days=1)\n",
    "            currentEnd = prev_day.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            currentEnd = earliestDate\n",
    "        print(\"the current end is: \", currentEnd)\n",
    "        df = pd.concat([df, currentData], ignore_index=True)\n",
    "        \n",
    "        \n",
    "    #the current end is the end with %Y-%m-%d format\n",
    "    currentEnd = end\n",
    "    while start not in currentEnd:\n",
    "        #get the data for the current date\n",
    "        currentData, earliestDate = pullData(ticker, apiKey, start=start, end=currentEnd, period = 'daily')\n",
    "        \n",
    "        # If earliestDate is the same as currentEnd, set currentEnd to 15:30:00 of the day before earliestDate\n",
    "        if earliestDate in currentEnd:\n",
    "            prev_day = datetime.strptime(earliestDate, '%Y-%m-%d') - timedelta(days=1)\n",
    "            currentEnd = prev_day.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            currentEnd = earliestDate\n",
    "        print(\"the current end is: \", currentEnd)\n",
    "        df = addLastEntry(df, currentData)\n",
    "        \n",
    "    #sort the dataframe by date\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    #remove duplicates based on date\n",
    "    df = df.drop_duplicates(subset='date')\n",
    "    #push it to the postgres database\n",
    "    push_to_pgsql(df, ticker)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9151580",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\"\n",
    "end_date='2025-05-31'\n",
    "\n",
    "data = get30MinData(api_key, ticker,end_date)\n",
    "    \n",
    "\n",
    "\n",
    "# Save to CSV if data was retrieved\n",
    "if not data.empty:\n",
    "    fileName = f\"{ticker}_30Min_data.csv\"\n",
    "    data.to_csv(fileName, index=False)\n",
    "    print(f\"Data saved to {fileName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting a switch case for hourly and daily data url\n",
    "\n",
    "base_url = \"https://financialmodelingprep.com/stable/stock-list?apikey={api_key}\"\n",
    "\n",
    "def get_stock_list(base_url):\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            return pd.DataFrame(data)\n",
    "        except ValueError:\n",
    "            print(\"JSON decoding failed\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "# Example usage\n",
    "stock_list_df = get_stock_list(base_url)\n",
    "\n",
    "#remove all values that have ETF in their symbol or companyName\n",
    "stock_list_df = stock_list_df[~stock_list_df['symbol'].str.contains('ETF', na=False)]\n",
    "stock_list_df = stock_list_df[~stock_list_df['companyName'].str.contains('ETF', na=False)]\n",
    "\n",
    "print(len(stock_list_df), \" stocks found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97681939",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://financialmodelingprep.com/stable/company-screener?country=US&isEtf=false&isFund=false&isActivelyTrading=true&apikey={api_key}\"\n",
    "\n",
    "def get_company_screener(baseurl):\n",
    "    response = requests.get(baseurl)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            return pd.DataFrame(data)\n",
    "        except ValueError:\n",
    "            print(\"JSON decoding failed\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "# Example usage\n",
    "company_screener_df = get_company_screener(baseurl)\n",
    "print(len(company_screener_df), \" companies found in the screener.\")\n",
    "# Remove all values that have ETF in their symbol or companyName\n",
    "company_screener_df = company_screener_df[~company_screener_df['symbol'].str.contains('ETF', na=False)]\n",
    "company_screener_df = company_screener_df[~company_screener_df['companyName'].str.contains('ETF', na=False)]\n",
    "print(len(company_screener_df), \" companies found in the screener.\")\n",
    "print(company_screener_df.columns)\n",
    "\n",
    "#make a copy which is sorted according to marketCap\n",
    "sorted_company_screener_df = company_screener_df.copy()\n",
    "sorted_company_screener_df['marketCap'] = pd.to_numeric(sorted_company_screener_df['marketCap'], errors='coerce')\n",
    "sorted_company_screener_df.sort_values(by='marketCap', ascending=False, inplace=True)\n",
    "\n",
    "#make a copy which is sorted according to price\n",
    "sorted_company_screener_df_price = company_screener_df.copy()\n",
    "sorted_company_screener_df_price['price'] = pd.to_numeric(sorted_company_screener_df_price['price'], errors='coerce')\n",
    "sorted_company_screener_df_price.sort_values(by='price', ascending=False, inplace=True)\n",
    "\n",
    "print(len(company_screener_df), \" companies found.\")\n",
    "\n",
    "# Save the all the variations of company_screener_df to CSV files\n",
    "company_screener_df.to_csv(\"company_screener.csv\", index=False)\n",
    "sorted_company_screener_df.to_csv(\"company_screener_sorted_by_marketCap.csv\", index=False)\n",
    "sorted_company_screener_df_price.to_csv(\"company_screener_sorted_by_price.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5653a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerCounter = 0\n",
    "#getting hourly data for all the stocks in company_screener_df\n",
    "while tickerCounter <= 100:\n",
    "    for index, row in sorted_company_screener_df.iterrows():\n",
    "        \n",
    "        print(f\"Ticker Counter: {tickerCounter}\")\n",
    "        ticker = row['symbol']\n",
    "        #check if the ticker is already in the file\n",
    "        fileName = f\"{ticker}_30Min_data.csv\"\n",
    "        if os.path.exists(fileName):\n",
    "            print(f\"Data for {ticker} already exists in {fileName}. Skipping...\")\n",
    "            tickerCounter += 1\n",
    "            continue\n",
    "        print(f\"Getting data for {ticker}...\")\n",
    "        try:\n",
    "            df = get30MinData(api_key, ticker, end_date)\n",
    "            if not df.empty:\n",
    "                fileName = f\"{ticker}_30Min_data.csv\"\n",
    "                df.to_csv(fileName, index=False)\n",
    "                print(f\"Data saved to {fileName}\")\n",
    "                tickerCounter += 1\n",
    "            else:\n",
    "                print(f\"No data found for {ticker}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "            \n",
    "#revert the tickerCounter to 0\n",
    "tickerCounter = 0\n",
    "#reverse the sorted_company_screener_df\n",
    "reverse_sorted_company_screener_df = company_screener_df.copy()\n",
    "reverse_sorted_company_screener_df['marketCap'] = pd.to_numeric(sorted_company_screener_df['marketCap'], errors='coerce')\n",
    "reverse_sorted_company_screener_df.sort_values(by='marketCap', ascending=True, inplace=True)\n",
    "\n",
    "#getting hourly data for all the stocks in company_screener_df\n",
    "while tickerCounter <= 100:\n",
    "    for index, row in sorted_company_screener_df.iterrows():\n",
    "        ticker = row['symbol']\n",
    "        #check if the ticker is already in the file\n",
    "        fileName = f\"{ticker}_30Min_data.csv\"\n",
    "        if os.path.exists(fileName):\n",
    "            print(f\"Data for {ticker} already exists in {fileName}. Skipping...\")\n",
    "            tickerCounter += 1\n",
    "            continue\n",
    "        print(f\"Getting data for {ticker}...\")\n",
    "        try:\n",
    "            df = get30MinData(api_key, ticker, end_date)\n",
    "            if not df.empty:\n",
    "                fileName = f\"{ticker}_30Min_data.csv\"\n",
    "                df.to_csv(fileName, index=False)\n",
    "                print(f\"Data saved to {fileName}\")\n",
    "                tickerCounter += 1\n",
    "            else:\n",
    "                print(f\"No data found for {ticker}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")      \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f5d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
